# AI ç”»åƒç”Ÿæˆå®Ÿè£…ã‚¬ã‚¤ãƒ‰

> æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€å®Ÿéš›ã® AI ç”»åƒç”Ÿæˆæ©Ÿèƒ½ï¼ˆå•†å“ç½®æ›ã€ã‚¤ãƒ³ãƒšã‚¤ãƒ³ãƒ†ã‚£ãƒ³ã‚°ï¼‰ã®å®Ÿè£…æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™

---

## ğŸ“‹ æ¦‚è¦

ç¾åœ¨ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ãƒ¢ãƒƒã‚¯ç”»åƒã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚å®Ÿéš›ã®å•†å“ç½®æ›æ©Ÿèƒ½ã‚’å®Ÿç¾ã™ã‚‹ã«ã¯ã€AI ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯å¤–éƒ¨ API ã®çµ±åˆãŒå¿…è¦ã§ã™ã€‚

---

## ğŸ¯ æ–¹å¼ã®é¸æŠ

### æ–¹å¼ A: ãƒ­ãƒ¼ã‚«ãƒ« AI ãƒ¢ãƒ‡ãƒ« (Stable Diffusion)

**ãƒ¡ãƒªãƒƒãƒˆ**:
- âœ… å®Œå…¨ãªåˆ¶å¾¡
- âœ… API è²»ç”¨ä¸è¦
- âœ… ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- âŒ GPU ãŒå¿…è¦ (NVIDIA, 8GB+ VRAM)
- âŒ è¤‡é›‘ãªç’°å¢ƒè¨­å®š
- âŒ å‡¦ç†é€Ÿåº¦ãŒé…ã„ (GPU ãªã—ã®å ´åˆ)

**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯**:
```
Python 3.10+
PyTorch 2.0+
diffusers (Hugging Face)
transformers
accelerate
```

**å®Ÿè£…æ‰‹é †**:

#### 1. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
cd ai-service
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install diffusers transformers accelerate pillow
```

#### 2. ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
```python
from diffusers import StableDiffusionInpaintPipeline
import torch

# Stable Diffusion Inpainting ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
model_id = "runwayml/stable-diffusion-inpainting"
pipe = StableDiffusionInpaintPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
)
pipe = pipe.to("cuda")  # ã¾ãŸã¯ "cpu" (éå¸¸ã«é…ã„)
```

#### 3. main.py ã®æ›´æ–°
```python
from fastapi import FastAPI, UploadFile, File, Form
from diffusers import StableDiffusionInpaintPipeline
import torch
from PIL import Image
import io

app = FastAPI()

# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ (èµ·å‹•æ™‚)
pipe = StableDiffusionInpaintPipeline.from_pretrained(
    "runwayml/stable-diffusion-inpainting",
    torch_dtype=torch.float16,
).to("cuda")

@app.post("/generate")
async def generate_images(
    sample_ad: UploadFile = File(...),
    product_images: List[UploadFile] = File(default=[]),
    prompts_text: Optional[str] = Form(None)
):
    # 1. ã‚µãƒ³ãƒ—ãƒ«åºƒå‘Šã‚’èª­ã¿è¾¼ã‚€
    sample_img = Image.open(io.BytesIO(await sample_ad.read()))
    
    # 2. ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆ (ç‰©ä½“æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã€ä¾‹: SAM)
    mask = generate_mask(sample_img)  # å®Ÿè£…ãŒå¿…è¦
    
    # 3. å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‡¦ç†
    results = []
    if prompts_text:
        prompts = prompts_text.split('\n')
        for prompt in prompts:
            result = pipe(
                prompt=prompt,
                image=sample_img,
                mask_image=mask,
                num_inference_steps=50,
            ).images[0]
            results.append(result)
    
    # 4. ä¿å­˜ã—ã¦ URL ã‚’è¿”ã™
    return {"generated_images": save_images(results)}
```

#### 4. ç‰©ä½“æ¤œå‡ºã¨ãƒã‚¹ã‚¯ç”Ÿæˆ
**Segment Anything Model (SAM)** ã‚’ä½¿ç”¨:
```python
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator

sam = sam_model_registry["vit_h"](checkpoint="sam_vit_h.pth")
mask_generator = SamAutomaticMaskGenerator(sam)

def generate_mask(image):
    masks = mask_generator.generate(image)
    # ä¸»è¦ç‰©ä½“ã®ãƒã‚¹ã‚¯ã‚’é¸æŠ
    main_mask = select_main_object_mask(masks)
    return main_mask
```

---

### æ–¹å¼ B: å¤–éƒ¨ API (è¿…é€Ÿãªé–‹ç™ºã«æ¨å¥¨)

**ãƒ¡ãƒªãƒƒãƒˆ**:
- âœ… GPU ä¸è¦
- âœ… è¿…é€Ÿãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- âœ… é«˜å“è³ªãªçµæœ

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- âŒ API Key ãŒå¿…è¦
- âŒ ä½¿ç”¨é‡ã«å¿œã˜ãŸèª²é‡‘
- âŒ å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã¸ã®ä¾å­˜

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³ 1: Stability AI API

**æ–™é‡‘**: ~$0.002-0.01 per image

**å®Ÿè£…**:
```python
import requests
import os

STABILITY_API_KEY = os.getenv("STABILITY_API_KEY")

@app.post("/generate")
async def generate_images(...):
    url = "https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/image-to-image/masking"
    
    headers = {
        "Authorization": f"Bearer {STABILITY_API_KEY}",
        "Accept": "application/json"
    }
    
    files = {
        "init_image": sample_ad.file,
        "mask_image": mask_file,
    }
    
    data = {
        "text_prompts[0][text]": prompt,
        "cfg_scale": 7,
        "samples": 1,
    }
    
    response = requests.post(url, headers=headers, files=files, data=data)
    return response.json()
```

**ç™»éŒ²**: https://platform.stability.ai/

---

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³ 2: OpenAI DALL-E 3 API

**æ–™é‡‘**: $0.040-0.080 per image

**å®Ÿè£…**:
```python
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@app.post("/generate")
async def generate_images(...):
    # DALL-E 3 ã¯ inpainting ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ãŸã‚ã€edit æ©Ÿèƒ½ã‚’ä½¿ç”¨
    response = client.images.edit(
        image=sample_ad.file,
        mask=mask_file,
        prompt=prompt,
        n=1,
        size="1024x1024"
    )
    
    return {"image_url": response.data[0].url}
```

**ç™»éŒ²**: https://platform.openai.com/

---

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³ 3: Replicate API (æœ€ã‚‚ç°¡å˜)

**æ–™é‡‘**: $0.0023 per second

**å®Ÿè£…**:
```python
import replicate

@app.post("/generate")
async def generate_images(...):
    output = replicate.run(
        "stability-ai/stable-diffusion-inpainting:95b7223104132402a9ae91cc677285bc5eb997834bd2349fa486f53910fd68b3",
        input={
            "image": sample_ad_url,
            "mask": mask_url,
            "prompt": prompt,
        }
    )
    return {"image_url": output}
```

**ç™»éŒ²**: https://replicate.com/

---

## ğŸ”§ æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®çµ±åˆ

### 1. Backend (index.js) ã®æ›´æ–°

```javascript
app.post('/api/generate', upload.fields([...]), async (req, res) => {
    try {
        const sampleAd = req.files['sampleAd'][0];
        const productImages = req.files['productImages'] || [];
        const { promptsText } = req.body;

        // FormData ã‚’ä½œæˆã—ã¦ AI Service ã«è»¢é€
        const formData = new FormData();
        formData.append('sample_ad', fs.createReadStream(sampleAd.path));
        
        if (promptsText) {
            formData.append('prompts_text', promptsText);
        }
        
        productImages.forEach(img => {
            formData.append('product_images', fs.createReadStream(img.path));
        });

        // AI Service ã‚’å‘¼ã³å‡ºã™
        const aiResponse = await axios.post(
            `${AI_SERVICE_URL}/generate`,
            formData,
            { headers: formData.getHeaders() }
        );

        res.json(aiResponse.data);
    } catch (error) {
        console.error(error);
        res.status(500).json({ error: 'Generation failed' });
    }
});
```

### 2. Frontend (App.tsx) ã®æ›´æ–°

```typescript
const handleGenerate = async () => {
    // ... ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ...
    
    setIsGenerating(true);
    setError(null);

    try {
        const formData = new FormData();
        formData.append('sampleAd', sampleAd[0]);
        productImages.forEach(file => formData.append('productImages', file));
        formData.append('promptsText', prompts);

        const response = await fetch('http://localhost:3000/api/generate', {
            method: 'POST',
            body: formData,
        });

        const data = await response.json();
        
        if (data.generated_images) {
            setGeneratedImages(data.generated_images);
            // å±¥æ­´ã«ä¿å­˜
            await saveToHistory({
                sampleAdName: sampleAd[0].name,
                promptsText: prompts,
                generatedImages: data.generated_images,
            });
        }
        
        setIsGenerating(false);
    } catch (err) {
        setError('Generation failed');
        setIsGenerating(false);
    }
};
```

---

## ğŸ“Š QA ã‚¹ã‚³ã‚¢ã®å®Ÿè£…

### OpenCV ã‚’ä½¿ç”¨ã—ãŸå“è³ªæŒ‡æ¨™ã®è¨ˆç®—

```python
import cv2
import numpy as np

def calculate_qa_score(original, generated):
    # 1. æ§‹é€ é¡ä¼¼åº¦ (SSIM)
    from skimage.metrics import structural_similarity as ssim
    ssim_score = ssim(original, generated, multichannel=True)
    
    # 2. ã‚¨ãƒƒã‚¸æ¤œå‡º (ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆæ¤œå‡º)
    edges_orig = cv2.Canny(original, 100, 200)
    edges_gen = cv2.Canny(generated, 100, 200)
    edge_diff = np.sum(np.abs(edges_orig - edges_gen))
    artifact_score = 1 - (edge_diff / edges_orig.size)
    
    # 3. è‰²æ¸©åº¦ã®ä¸€è²«æ€§
    color_diff = np.mean(np.abs(original - generated))
    color_score = 1 - (color_diff / 255)
    
    # ç·åˆã‚¹ã‚³ã‚¢
    qa_score = (ssim_score * 0.4 + artifact_score * 0.3 + color_score * 0.3)
    
    return {
        "overall": qa_score,
        "ssim": ssim_score,
        "artifact": artifact_score,
        "color": color_score
    }
```

---

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ã®æ¨å¥¨äº‹é …

### Docker åŒ–

**Dockerfile (ai-service)**:
```dockerfile
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

RUN apt-get update && apt-get install -y python3.10 python3-pip

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**docker-compose.yml**:
```yaml
version: '3.8'
services:
  frontend:
    build: ./frontend
    ports:
      - "5173:5173"
  
  backend:
    build: ./backend
    ports:
      - "3000:3000"
    environment:
      - AI_SERVICE_URL=http://ai-service:8000
  
  ai-service:
    build: ./ai-service
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

---

## ğŸ’° ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

### ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤
- GPU: RTX 3060 (12GB) ~$300-400
- é›»æ°—ä»£: ~$0.10/hour
- **é©åˆ**: å¤§é‡ä½¿ç”¨ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼è¦ä»¶

### API ã‚µãƒ¼ãƒ“ã‚¹ (æœˆé–“ 1000 æšã®ç”»åƒ)
- Stability AI: ~$2-10
- OpenAI DALL-E: ~$40-80
- Replicate: ~$5-15
- **é©åˆ**: ãƒ†ã‚¹ãƒˆã€å°è¦æ¨¡ä½¿ç”¨

---

## ğŸ“š å‚è€ƒãƒªã‚½ãƒ¼ã‚¹

- [Stable Diffusion Inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting)
- [Segment Anything Model](https://github.com/facebookresearch/segment-anything)
- [Stability AI API Docs](https://platform.stability.ai/docs/api-reference)
- [OpenAI Image API](https://platform.openai.com/docs/guides/images)
- [Replicate Docs](https://replicate.com/docs)

---

## âœ… æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **æ–¹å¼ã®é¸æŠ**: ãƒ­ãƒ¼ã‚«ãƒ« vs API
2. **èªè¨¼æƒ…å ±ã®å–å¾—**: API Key (API ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ)
3. **ai-service/main.py ã®æ›´æ–°**
4. **ãƒ†ã‚¹ãƒˆ**: å˜ä¸€ç”»åƒã®ç”Ÿæˆ
5. **çµ±åˆ**: Backend ã¨ Frontend ã®æ¥ç¶š
6. **æœ€é©åŒ–**: ãƒãƒƒãƒå‡¦ç†ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥
